{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homewok 6     Songhao Jiang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "$\\theta: spicy\\hspace{1cm}20-\\theta: plain \\hspace{1cm} x:plain \\hspace{1cm} 5-x:spicy$ \n",
    "\n",
    "This is a hypergeometric distribution and therefore the likelihood function for $\\theta$ is:\n",
    "\n",
    "$L(\\theta) = \\frac{{\\theta \\choose 5-x}{20-\\theta \\choose x}}{{20 \\choose 5}}$\n",
    "\n",
    "We want to maximize the likelihood, and we can look at the ratio of the likelihood values for successive value:\n",
    "\n",
    "$\\frac{L(\\theta)}{L(\\theta - 1)}$\n",
    "\n",
    "$\\Rightarrow \\frac{\\frac{{\\theta \\choose 5-x}{20-\\theta \\choose x}}{{20 \\choose 5}}}{\\frac{{\\theta-1 \\choose 5-x}{21-\\theta \\choose x}}{{20 \\choose 5}}}$\n",
    "$\\Rightarrow \\frac{{\\theta \\choose 5-x}{20-\\theta \\choose x}}{{\\theta-1\\choose 5-x}{21-\\theta\\choose x}}$\n",
    "$\\Rightarrow \\frac{(\\theta)!}{(5-x)!(\\theta+x-5)!}\\frac{(20-\\theta)!}{(x)!(20-\\theta-x)!}\\div\\frac{(\\theta-1)!}{(5-x)!(\\theta-6+x)!}\\div\\frac{(21-\\theta)!}{(x)!(21-\\theta-x)!}$\n",
    "$\\Rightarrow \\frac{\\theta(21-\\theta-x)}{(21-\\theta)(\\theta+x-5)}$\n",
    "\n",
    "it exceeds $1$ iff $\\theta(21-\\theta-x)>(21-\\theta)(\\theta+x-5) \\Rightarrow \\theta < 21-4.2x$ \n",
    "\n",
    "If smaller than the value, the ratio will $>1$, otherwise the ratio will $<1$, which means that there is a place in the middle which has the maximum\n",
    "\n",
    "So $\\hat{\\theta} = [21-4.2x]$ $\\Rightarrow$ the integer part of $21-4.2x$\n",
    "\n",
    "### 2\n",
    "x: total number of plain meatballs after 5 draws\n",
    "\n",
    "let $p$ equals the probability of choosing a plain meatball\n",
    "\n",
    "This is a binomial distribution and therefore we will have:\n",
    "\n",
    "$L(p)$ = $n\\choose x$ $p^x(1-p)^{n-x}$\n",
    "\n",
    "The log likelihood is $ln(L(p) = ln$$n\\choose x$ + $xln(p) + (n-x)ln(1-p) = \\frac{x}{p} - \\frac{n-x}{1-p} = 0$\n",
    "\n",
    "$\\Rightarrow p = \\frac{x}{n}$\n",
    "\n",
    "For this problem $n=5$ and $p=\\frac{20-\\theta}{20}$\n",
    "\n",
    "And therefore we will have $\\hat{\\theta} = 20 - 4x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "let $\\lambda$ be the mean of length of time until a rip happens.\n",
    "\n",
    "let $y_i$ be each experiment's length of time until a rip happens\n",
    "\n",
    "in this case we will have $y_1 = x_1$, $y_2 = x_2 - x_1$ $\\dots$ $y_k = x_k - x_{k-1}$\n",
    "\n",
    "$\\Rightarrow L(\\lambda) = \\lambda e^{-\\lambda y_1}\\dots\\lambda e^{-\\lambda y_k} = \\lambda^ke^{-\\lambda \\sum_{i=1}^{k}y_i}$\n",
    "\n",
    "take ln and take direvative w.r.t $\\lambda$ $\\Rightarrow ln(L(\\lambda)) = \\frac{k}{\\lambda} - \\sum_{i=1}^{k}y_i$\n",
    "\n",
    "and since $\\sum_{i=1}^{k}y_i = x_k$, then we will have $ln(L(\\lambda)) = \\frac{k}{\\lambda} - x_k$\n",
    "\n",
    "set it to zero, we will get $\\hat{\\lambda} = \\frac{k}{x_k}$\n",
    "\n",
    "### 2\n",
    "suppose the times recorded are $x_1 \\leq x_2 \\leq \\dots x_r \\leq H$ for some known r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X_i \\thicksim N(\\mu_1, \\sigma^2)$\n",
    "\n",
    "$Y_i \\thicksim N(\\mu_2, \\sigma^2)$\n",
    "\n",
    "$G_i \\thicksim N(\\mu_1-\\mu_2, \\sigma^2)$\n",
    "\n",
    "Generally the log likelihood of the joint distribution of $X, Y, G$ should be \n",
    "\n",
    "$-\\frac{n}{2}ln(2\\pi)-\\frac{n}{2}ln(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu_1)^2 -\\frac{n}{2}ln(2\\pi)-\\frac{n}{2}ln(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(y_i-\\mu_2)^2 -\\frac{n}{2}ln(2\\pi)-\\frac{n}{2}ln(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(g_i-\\mu)^2 $\n",
    "$=-\\frac{n}{2}ln(2\\pi)-\\frac{n}{2}ln(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu_1)^2 -\\frac{n}{2}ln(2\\pi)-\\frac{n}{2}ln(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(y_i-\\mu_2)^2 -\\frac{n}{2}ln(2\\pi)-\\frac{n}{2}ln(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(g_i-\\mu_1 + \\mu_2)^2$ \n",
    "\n",
    "### 1\n",
    "take the direvative w.r.t $\\mu_1$\n",
    "\n",
    "$\\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(x_i - \\mu_1) + \\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(g_i - \\mu_1 + \\mu_2)$\n",
    "\n",
    "$\\sum_{i=1}^{n}x_i - n\\mu_1 + \\sum_{i=1}^{n}g_i-n\\mu_1 + n\\mu_2 = 0$\n",
    "\n",
    "$\\hat{\\mu_1}=\\frac{\\bar{X}+\\bar{G}+\\mu_2}{2}$\n",
    "\n",
    "### 2\n",
    "take the direvative w.r.t $\\mu_2$\n",
    "\n",
    "$\\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(y_i - \\mu_2) - \\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(g_i - \\mu_1 + \\mu_2)$\n",
    "\n",
    "$\\sum_{i=1}^{n}y_i - n\\mu_2 - \\sum_{i=1}^{n}g_i + n\\mu_1 - n\\mu_2 = 0$\n",
    "\n",
    "$\\hat{\\mu_2}=\\frac{\\bar{Y}-\\bar{G}+\\mu_1}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "let $X_1 \\dots X_n$ be random sample follow this distribution, then we will have \n",
    "\n",
    "$E[X] = \\frac{1}{p} = \\mu \\Rightarrow p = \\frac{1}{\\mu}$\n",
    "\n",
    "And therefore the method of moments estimate should be \n",
    "\n",
    "$\\hat{p} = \\frac{1}{\\bar{X}}$\n",
    "\n",
    "Where $\\bar{X} = \\frac{\\sum_{i=1}^{n}X_i}{n}$\n",
    "\n",
    "### 2\n",
    "$L(p) = ln\\prod_{i=1}^{n}p(1-p)^{X_i-1}=\\sum_{i=1}^{n}(lnp + X_iln(1-p) - ln(1-p))$\n",
    "\n",
    "$\\Rightarrow nln(p)- nln(1-p) + n\\bar{X}ln(1-p)$\n",
    "\n",
    "take the direvative w.r.t $p$ and set it equal to $0$\n",
    "\n",
    "$\\frac{n}{p}-\\frac{n}{1-p}-\\frac{n\\bar{X}}{1-p} = 0$\n",
    "\n",
    "$\\Rightarrow \\hat{p} = \\frac{1}{\\bar{X}}$\n",
    "\n",
    "Where $\\bar{X} = \\frac{\\sum_{i=1}^{n}X_i}{n}$\n",
    "\n",
    "\n",
    "### 3\n",
    "$MSE(\\hat{\\theta}) = Var(\\hat{\\theta}) + Bias(\\hat{\\theta}, \\theta)^2$\n",
    "\n",
    "Obviously the mle estimator is unbiased so we are only left with $MSE(\\hat{\\theta}) = Var(\\hat{\\theta})$\n",
    "\n",
    "For variance we will use the formular: $Var(\\hat{\\theta}) = \\frac{1}{nI(p)}$\n",
    "\n",
    "where $I(p) = -E[\\frac{\\partial^2}{\\partial p^2}ln(f(X|p)]$\n",
    "\n",
    "$ln(f(X|p) = ln(p) + (X-1)ln(1-p)$\n",
    "\n",
    "$\\frac{\\partial}{\\partial p}ln(f(X|p) = \\frac{1}{p} - \\frac{X-1}{1-p}$\n",
    "\n",
    "$\\frac{\\partial^2}{\\partial p^2}ln(f(X|p) = -\\frac{1}{p^2} - \\frac{X-1}{(1-p^2)}$\n",
    "\n",
    "And therefore $I(p) = -(-\\frac{1}{p^2} - \\frac{E[X]-1}{(1-p)^2})$\n",
    "$=\\frac{1}{p^2} + \\frac{\\frac{1}{p}-1}{(1-p)^2} = \\frac{1}{(1-p)p^2}$\n",
    "\n",
    "and therefore $\\frac{1}{nI(p)} = Var(\\hat{\\theta}) = \\frac{(1-p)p^2}{n}$\n",
    "\n",
    "and therefore $MSE(\\hat{\\theta}) = \\frac{(1-p)p^2}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "let $X_1 \\dots X_n$ be random sample follow this distribution, then we will have \n",
    "\n",
    "since $f(x)$ is a odd function and therefore $E[X] = 0$\n",
    "\n",
    "Then is for $E[X^2] = \\int_{-\\infty}^{\\infty}x^2f(x)dx$\n",
    "\n",
    "Here we should also notice that the $x^2f(x)$ is an even function, and therefore we can simply the integral to\n",
    "\n",
    "$2\\int_{0}^{\\infty} x^2\\frac{e^{-\\frac{x}{\\sigma}}}{2\\sigma}dx = \\int_{0}^{\\infty} x^2\\frac{e^{\\frac{-x}{\\sigma}}}{\\sigma}dx$\n",
    "$=\\left[-e^{-\\frac{x}{\\sigma}}(2\\sigma^2+2x\\sigma+x^2)\\right]_{0}^{\\infty} = 2\\sigma^2$\n",
    "\n",
    "And therefore we will have $E[X^2] = 2\\sigma^2 = \\mu = \\frac{\\sum_{i=1}^{n}X_i^2}{n}$\n",
    "\n",
    "So $\\sigma = \\sqrt{\\frac{\\mu}{2}}$ \n",
    "\n",
    "And the method of moments estimator is\n",
    "\n",
    "$\\hat{\\sigma} = \\sqrt{\\frac{\\bar{X^2}}{2}}$\n",
    "where $\\bar{X^2} = \\frac{\\sum_{i=1}^{n}X_i^2}{n}$\n",
    "\n",
    "### 2\n",
    "$ln(L(p)) = ln\\prod_{i=1}^{n}\\frac{e^{\\frac{-|X_i|}{\\sigma}}}{2\\sigma} = \\sum_{i=1}^{n}(-ln2 - ln\\sigma - \\frac{|X_i|}{\\sigma}) = -nln2 - nln\\sigma - \\frac{\\sum_{i=1}^{n}|X_i|}{\\sigma}$\n",
    "\n",
    "take the direvative w.r.t $\\sigma$ and set it equal to $0$\n",
    "\n",
    "$-\\frac{n}{\\sigma} + \\frac{\\sum_{i=1}^{n}|X_i|}{\\sigma^2} = 0$\n",
    "\n",
    "$\\Rightarrow \\hat{\\sigma} = \\frac{\\sum_{i=1}^{n}|X_i|}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 \n",
    "let $X_1 \\dots X_n$ be random sample follow this distribution, then we will have \n",
    "\n",
    "$\\mu = E[X] = \\int_{\\theta}^{\\infty}xe^{-(x-\\theta)}dx = e^{\\theta}\\int_{\\theta}^{\\infty}xe^{-x}dx$\n",
    "\n",
    "we need to solve $\\int_{\\theta}^{\\infty}xe^{-x}dx$\n",
    "\n",
    "by integral by parts, let $f=x, df=dx, dg=e^{-x}dx, g=-e^{-x}$\n",
    "\n",
    "we will have $-e^{-x}x + \\int_{}{}e^{-x}dx = e^{-x}(-x-1)$\n",
    "\n",
    "And therefore $\\int_{\\theta}^{\\infty}xe^{-x}dx = \\left[e^{-x}(-x-1)\\right]_{\\theta}^{\\infty} = (\\theta+1)e^{-\\theta}$\n",
    "\n",
    "put this back to $\\mu$\n",
    "\n",
    "$\\Rightarrow \\mu = \\theta + 1 \\Rightarrow \\theta = \\mu - 1 \\Rightarrow \\hat{\\theta} = \\bar{X} - 1$\n",
    "\n",
    "where $\\bar{X} = \\frac{\\sum_{i=1}^{n}X_i}{n}$\n",
    "\n",
    "### 2\n",
    "$ln(L(\\theta)) = -(\\sum_{i=1}^{n}X_i - n\\theta)$\n",
    "\n",
    "take the direvative w.r.t $\\theta$ we will have $\\sum_{i=1}^{n}X_i - n = 0$\n",
    "\n",
    "The equation does not lead to resonable solutions.\n",
    "\n",
    "Instead we would be able to calculate the likelihood function in this way\n",
    "\n",
    "$L(\\theta) = \\prod_{i=1}^{n}\\mathbb{1}(X_i \\geq \\theta)e^{-X_i + \\theta} = \\mathbb{1}(X_i \\geq \\theta)e^{-\\sum_{i=1}^{n}X_i + n\\theta}$\n",
    "\n",
    "And therefore since $e^{-n\\bar{X} + n\\theta}$ is an increasing function, if we want to maximize the likelihood itself,\n",
    "\n",
    "we would like to maximize $\\mathbb{1}(X_i \\geq \\theta)$, which means that we do not want it equal to zero\n",
    "\n",
    "And therefore we must let all $X_i \\geq \\theta$\n",
    "\n",
    "and therefore we will take $\\hat{\\theta} = min(X_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=read.table(\"RobotReactTime.txt\", header=T)\n",
    "t1=t$Time[t$Robot==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 28.4738 \n",
      "beta 32.57074 \n",
      "lambda 0.03276296 \n"
     ]
    }
   ],
   "source": [
    "lower = mean(t1) - sqrt(3*sd(t1)^2)\n",
    "cat(\"alpha\", lower, \"\\n\")\n",
    "upper = mean(t1) + sqrt(3*sd(t1)^2)\n",
    "cat(\"beta\", upper, \"\\n\")\n",
    "lambda = 1/mean(t1)\n",
    "cat(\"lambda\", lambda, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80th for uniform 31.75135 \n",
      "80th for exponential 49.1237 \n"
     ]
    }
   ],
   "source": [
    "cat(\"80th for uniform\",qunif(0.8, lower, upper), \"\\n\")\n",
    "cat(\"80th for exponential\",qexp(0.8, lambda), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for uniform 0.3115001 \n",
      "probability for exponential 0.02030626 \n"
     ]
    }
   ],
   "source": [
    "cat(\"probability for uniform\", punif(29.75, lower, upper) - punif(28.15, lower, upper), \"\\n\")\n",
    "cat(\"probability for exponential\", pexp(29.75, lambda) - pexp(28.15, lambda), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical 80th 31.522 \n",
      "empirical probability 0.2727273 \n"
     ]
    }
   ],
   "source": [
    "cat(\"empirical 80th\", quantile(t1, 0.8), \"\\n\")\n",
    "cat(\"empirical probability\", sum(t1>=28.15&t1<=29.75)/length(t1), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
