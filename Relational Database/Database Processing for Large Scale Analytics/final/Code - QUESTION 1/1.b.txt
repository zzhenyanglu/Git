# ------------------------------------------------------------------------------------------------

# NOTICE: this part of script is from assignment 6. The three tables below are not complete. 
#         I have made certain changes to the three tables in question 1.c, next part, to make it more  
#         fit for this final Assignment, so the following script actually is just for this question. 
#         Please don't run it before running other questions of this final assignment, or you will be 
#         warned by PYTHON that Tuple is out of range in certain questions!  Thank you!     


#-------------------------------------------------------------------------------------------------





import urllib2, time, json, sqlite3

conn = sqlite3.connect('CSC455-Final.db')
c = conn.cursor()
wFD = urllib2.urlopen('http://rasinsrv07.cstcis.cti.depaul.edu/CSC455/Twitter_2013_11_12.txt')

numLines = 100000 # how many tweets you want to read

createTable = '''CREATE TABLE Tweets (
                 ID          NUMBER(20),
                 Created_At  DATE,
                 Text        CHAR(141),

                 Source VARCHAR(200),
                 In_Reply_to_User_ID NUMBER(20),
                 Retweet_Count NUMBER(10),
                  
                 CONSTRAINT Tweets_PK  PRIMARY KEY (id)
              );'''

createTable2 = '''CREATE TABLE Geo (
                 ID          Number(20), 
                 Type        Varchar2(20),
                 Latitute    number(10),
                 Longitute   number(10),

                 CONSTRAINT geo_PK  PRIMARY KEY(ID)
              );'''

createTable3 = '''CREATE TABLE user_entry (
                  id Number(20),
                  name Varchar2(50),
                  screen_name Varchar2(50),
                  description varchar(200),
                  friends_count Number(4));'''

conn.execute('DROP TABLE IF EXISTS Tweets');
conn.execute(createTable)
conn.execute('DROP TABLE IF EXISTS Geo');
conn.execute(createTable2)
conn.execute('''drop table if exists user_entry''')
conn.execute(createTable3)


def readTweets(fd, numLines, output = ''):
    
    if output:
        outFD = open(output, 'w')

    while numLines > 0:
        line = fd.readline()
        numLines = numLines - 1
        tweet = json.loads(line)

        value_tweets =[]
        value_geo = []
        value_user_entry = []

        value_tweets.append(map(lambda x : None if tweet[x] in ['',[]] else tweet[x], ['id', 'created_at', 'text', 'source', 'in_reply_to_user_id', 'retweet_count']))
        value_user_entry.append([tweet['user']['id'],tweet['user']['name'],tweet['user']['screen_name'],tweet['user']['description'],tweet['user']['friends_count']])

        
        if tweet['place'] is not None:    # for entries going into geo table
            record = tweet['place'].pop('bounding_box')
            if record is not None:
                d=str(abs(record['coordinates'][0][0][1]))+str(abs(record['coordinates'][0][0][0]))
                value_geo.append([d,record['type'],record['coordinates'][0][0][1],record['coordinates'][0][0][0]])

        conn.executemany('INSERT OR IGNORE INTO Tweets VALUES(?,?,?,?,?,?)', value_tweets)
        conn.executemany('INSERT OR IGNORE INTO Geo VALUES(?,?,?,?)', value_geo)
        conn.executemany('INSERT OR IGNORE INTO User_entry VALUES(?,?,?,?,?)', value_user_entry)
        outFD.write(line)

start = time.time()
readTweets(wFD, numLines, 'tweet_output.txt')
end   = time.time()
print "readTweets took ", (end-start), ' seconds.'

wFD.close()
conn.commit()
#conn.close()


# readTweets took  423.491999865  seconds.